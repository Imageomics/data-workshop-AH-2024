{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-State Our Goal\n",
    "*Goal:* We want to use Shaggy's dataset to train a male/female butterfly classifier. And we need to describe the dataset work that Shaggy's done.\n",
    "\n",
    "### State Our Assumptions About the Dataset\n",
    "When we started, our assumptions were:\n",
    "- Shaggy's dataset is derived from Kydoimos\n",
    "- No changes have been made to the image data content\n",
    "- No images have been added or removed\n",
    "- Each component of Shaggy's dataset can be linked to its corresponding component into the source dataset (provenance is intact)\n",
    "- Test/train splits are done appropriately\n",
    "\n",
    "Apparently, some, or all of these assumptions weren't accurate.\n",
    "\n",
    "### Make an Intermediate Goal\n",
    "*Goal:* We want to see if we can re-link Shaggy's work to the original dataset.</br>\n",
    " To test which of our assumptions are off, let's do the following:\n",
    "1. Download the original/upstream/source dataset (Kydoimos)\n",
    "2. Load Shaggy's dataset\n",
    "3. Run MD5 checksums on all images in Kydoimos and Shaggy's dataset\n",
    "4. Merge on MD5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import hashlib\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from PIL.TiffTags import TAGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download the original/upstream/source dataset (Kydoimos) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The upstream dataset is on Hugging Face: https://huggingface.co/datasets/johnbradley/Kydoimos\n",
    "\n",
    "dataset_path = \"johnbradley/Kydoimos\"\n",
    "\n",
    "# Note that if the dataset does not load using the dataset ID above, try the following two lines instead:\n",
    "# !git clone https://huggingface.co/datasets/johnbradley/Kydoimos ../../Kydoimos\n",
    "# dataset_path = \"../../Kydoimos\"\n",
    "\n",
    "kydoimos = load_dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the upstream dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the upstream dataset contents\n",
    "# Note that the full dataset is in the 'train' split only because that is the default split when loading the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a sample image, say, index 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See that the image is a PIL object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the upstream dataset into a Pandas dataframe for simpler exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kydoimos_df = pd.DataFrame(kydoimos['train'])\n",
    "# This command loads the image data into the dataframe as a column. This is not recommended for large datasets. Since our dataset is small, it's OK.\n",
    "\n",
    "\n",
    "# To make a dataframe without the image column, use the following command instead: \n",
    "\n",
    "# kydoimos_df = pd.DataFrame(kydoimos['train'].remove_columns(['image'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kydoimos_df.nunique() # Note that this gives an error due to the 'image' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Shaggy's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the metadata table into a dataframe\n",
    "shaggy_dir = '../../Shaggy/'\n",
    "shaggy_df = pd.read_csv(os.path.join(shaggy_dir, 'metadata.csv'), encoding = 'utf-8', low_memory=False)\n",
    "\n",
    "# Add a column showing how to get to each image from here.\n",
    "shaggy_df['rel_file_path'] = shaggy_dir + shaggy_df['file_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run MD5 checksums on all images in Kydoimos and Shaggy's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD5 checksum practice ...\n",
    "\n",
    "\n",
    "# Note that a small change in the data will result in a completely different checksum.\n",
    "\n",
    "# Review the 'further-reading.ipynb' notebook for more info on computing MD5 checksums."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create functions for MD5 checksums\n",
    "\n",
    "# For use with reading files from disk\n",
    "\n",
    "\n",
    "# For use with PIL image objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MD5 checksum on Shaggy's and Kydoimos datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the MD5 checksums, we can save them to a CSV file for future use (omitting the 'image' column).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Merge the datasets on MD5 to link them together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No matches???\n",
    "Like, zoinks Scooby. Something is strange here.\n",
    "\n",
    "There must be something about the image data that has been changed between the Kydoimos dataset and Shaggy's dataset.\n",
    "\n",
    "Let's list out the things that could affect the MD5 checksum on the binary data for two images:\n",
    "- Image data content (resizing, cropping, color changes, compression, corruption)\n",
    "- Image intrinsic metadata\n",
    "\n",
    "As a shortcut for this class, we'll skip the detective work and get to the solution:\n",
    "\n",
    "*The intrinsic metadata is changed when the image is loaded as a PIL object, which was done automatically with the Kydoimos dataset by the `datasets` library.*\n",
    "\n",
    "To address this, we'll load Shaggy's dataset with PIL before taking MD5s again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The plan for this cell is to load the images from disk into the dataframe as PIL objects and compute the MD5 checksums.\n",
    "# Expect this cell to yield an UnidentifiedImageError: cannot identify image file '<path-to->/amalfreda_0.tif'\n",
    "# We also got a warning stating \"UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get a fresh preview at the dataframe:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can try to open the individual image causing a problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Let's look through the whole set of Shaggy's images and verify the data integrity for each ...\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to each image path in the DataFrame\n",
    "\n",
    "# Optionally, you can drop the 'valid_image' column if it's no longer needed\n",
    "# shaggy_df.drop(columns=['valid_image'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to remove rows with corrupt images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can apply the `pil_md5_checksum` function (same as the code that failed above)\n",
    "\n",
    "\n",
    "# We can see below that the \"md5\" and \"pil_md5\" values for each entry are different. This is because the \"md5\" column was computed from the file on disk, while the \"pil_md5\" column was computed from the PIL image object. The PIL image object may have been modified in memory, which is why the checksums differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fix, 110 in kydoimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After fix, 107 in shaggy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retry the merge using the PIL checksums for each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# But Shaggy had 107 images ... where's the extra one hiding? Did something change size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find the images that don't match between the two datasets and display them\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looks like some of Shaggy's personal photos found their way into the dataset while he was organizing things ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove the images that don't match from the Shaggy dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Now the number of images in Shaggy's dataframe matches the number that were merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# However, we have more images in the merged dataframe compared to either input dataframe. There must be duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can identify the duplicates using the MD5 checksums for the PIL object form of each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a sample of the duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite a few duplicates come from the upstream dataset\n",
    "It looks like these are coming from unique \"id\" but identical \"NHM specimen number\" entries. \n",
    "\n",
    "Now that we know duplicates are an issue, we should check if we have duplicates between our test and train splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shaggy_dups\n",
    "\n",
    "# Filter groups where both 'test' and 'train' are present\n",
    "\n",
    "# Count the number of 'pil_md5' values present in both 'test' and 'train'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that there is data leakage between the test and train splits.\n",
    "That's the final nail in the coffin for Shaggy's dataset. \n",
    "At this point, it will be simpler to start over from Kydoimos and organize a new dataset."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
