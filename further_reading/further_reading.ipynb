{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad8b392-d8c2-4283-89cd-8ec738fa1b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "import hashlib\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from PIL.TiffTags import TAGS\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bcdfae-7afb-43a6-ab2e-5232e2fa21d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4852d91ba138438083b88054a350c430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/111 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The upstream dataset is on Hugging Face: https://huggingface.co/datasets/johnbradley/Kydoimos\n",
    "\n",
    "dataset_path = \"johnbradley/Kydoimos\"\n",
    "# !git clone https://huggingface.co/datasets/johnbradley/Kydoimos ../../Kydoimos\n",
    "# dataset_path = \"../../Kydoimos\"\n",
    "\n",
    "kydoimos = load_dataset(dataset_path)\n",
    "\n",
    "kydoimos_df = pd.DataFrame(kydoimos['train'])\n",
    "\n",
    "# Load the metadata table into a dataframe\n",
    "shaggy_dir = '../Shaggy/'\n",
    "shaggy_df = pd.read_csv(os.path.join(shaggy_dir, 'metadata.csv'), encoding = 'utf-8', low_memory=False)\n",
    "\n",
    "# Add a column showing how to get to each image from here.\n",
    "shaggy_df['rel_file_path'] = shaggy_dir + shaggy_df['file_name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6dd5f4-4aa2-499b-a45e-b442178cdf82",
   "metadata": {},
   "source": [
    "### A bit more on checksums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2115dd38-9b0a-4851-8308-69d0749aef6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for MD5 checksums\n",
    "\n",
    "# Below are a few implementations of an MD5 checksum that can be run on a file specified by a filepath.\n",
    "# Depending on the size of the file you want to calculate a checksum on, you may want to stream the calculation in chunks\n",
    "# to avoid using excessive memory. \n",
    "\n",
    "# Simple, but could cause OOM error on a massive file\n",
    "def file_md5_checksum(file_path):\n",
    "    hash = hashlib.md5()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        file_bytes = f.read()\n",
    "        hash.update(file_bytes)\n",
    "    checksum = hash.hexdigest()\n",
    "    return checksum\n",
    "\n",
    "# # Straight-forward, memory safe\n",
    "# def file_md5_checksum(file_path):\n",
    "#     hash = hashlib.md5()\n",
    "#     with open(file_path, \"rb\") as f:\n",
    "#         while True:\n",
    "#             chunk = f.read(4096)\n",
    "#             if not chunk:\n",
    "#                 break\n",
    "#             hash.update(chunk)\n",
    "#     checksum = hash.hexdigest()\n",
    "#     return checksum\n",
    "# \n",
    "# # Pythonic, memory safe\n",
    "# def file_md5_checksum(file_path):\n",
    "#     hash = hashlib.md5()\n",
    "#     with open(file_path, \"rb\") as f:\n",
    "#         for chunk in iter(lambda: f.read(4096), b\"\"):\n",
    "#             hash.update(chunk)\n",
    "#     checksum = hash.hexdigest()\n",
    "#     return checksum\n",
    "\n",
    "# Also make one for a PIL object as before.\n",
    "def pil_md5_checksum(image):\n",
    "    hash = hashlib.md5()\n",
    "    buffer = BytesIO()\n",
    "    image.save(buffer, format=image.format)\n",
    "    hash.update(buffer.getvalue())\n",
    "    checksum = hash.hexdigest()\n",
    "    return checksum\n",
    "\n",
    "# And an additional function to use use OpenCV.\n",
    "def cv2_md5_checksum(image):\n",
    "    hash = hashlib.md5()\n",
    "    image_bytes = image.tobytes()\n",
    "    hash.update(image_bytes)\n",
    "    checksum = hash.hexdigest()\n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beb0078-be1e-4aab-ad51-6741ce931ce9",
   "metadata": {},
   "source": [
    "For a single given image file, the calculated checksum (such as MD5) can be sensitive to the way the image data is loaded into memory.\n",
    "This is because the different image processing libraries (e.g., OpenCV, Pillow) may perform internal transformations or optimizations when loading the image data,\n",
    "which can result in minor differences in the raw byte representation of the image.\n",
    "These byte-level differences can then lead to different checksum values being calculated, even though the image content itself is the same.\n",
    "\n",
    "In this example, we demonstrate this effect by calculating the MD5 checksum for a TIFF image file using three different approaches:\n",
    "1. Loading the image using OpenCV's cv2.imread() function\n",
    "2. Loading the image using the Pillow (PIL) library's `Image.open()` function\n",
    "3. Directly reading the raw bytes of the image file\n",
    "\n",
    "The `cv2_md5_checksum()` function loads the image using OpenCV, converts the NumPy array representation to bytes, and then calculates the MD5 checksum of those bytes.\n",
    "The `pil_md5_checksum()` function performs a similar operation using the Pillow library.\n",
    "The `file_md5_checksum()` function directly reads the bytes of the image file and calculates the MD5 checksum of those raw bytes.\n",
    "\n",
    "When we print the resulting checksums, we see that the three different approaches produce different MD5 hash values, even though they are all operating on the same underlying image file.\n",
    "This is because the internal data representations and transformations performed by the different image processing libraries can introduce minor differences in the raw byte content.\n",
    "\n",
    "Understanding this sensitivity of checksums to the image loading method is important when working with image metadata, file integrity checks, or other applications where the calculated checksum needs to be consistent and reliable.\n",
    "\n",
    "The best way to handle this is to standardize the image loading approach or to account for these potential discrepancies when comparing checksum values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c62ea-d3cb-4a94-9713-ca535bb85be3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71728b84-b33e-4d55-aab5-c467a5ca5372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2: a2b85e3545d8b525fe20d90ebe5d847e\n",
      "pil: d0dd3bc05dead39e2177c59f2925cd2b\n",
      "raw: baf9cc4fd984f80dea07ec93308c3a7b\n"
     ]
    }
   ],
   "source": [
    "img_cv2 = cv2.imread('../Shaggy/images/amalfreda_1.tif')\n",
    "img_pil = Image.open('../Shaggy/images/amalfreda_1.tif')\n",
    "img_raw = '../Shaggy/images/amalfreda_1.tif'\n",
    "\n",
    "md5_cv2 = cv2_md5_checksum(img_cv2)\n",
    "md5_pil = pil_md5_checksum(img_pil)\n",
    "md5_raw = file_md5_checksum(img_raw)\n",
    "\n",
    "print(f\"cv2: {md5_cv2}\")\n",
    "print(f\"pil: {md5_pil}\")\n",
    "print(f\"raw: {md5_raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b43046-ca71-4a0c-884e-f857fd3dce8c",
   "metadata": {},
   "source": [
    "One of the differences that can make there way into the bytes representation of this data is the image metadata.\n",
    "We can inspect this on the raw image file as well as the PIL-loaded version. The OpenCV image is simply a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4495e623-ca0f-40b8-9d46-c51f323693f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for <PIL.TiffImagePlugin.TiffImageFile image mode=RGB size=124x64 at 0x1D96F23E2A0>:\n",
      " ImageWidth: (124,)\n",
      " ImageLength: (64,)\n",
      " BitsPerSample: (8, 8, 8)\n",
      " Compression: (1,)\n",
      " PhotometricInterpretation: (2,)\n",
      " ResolutionUnit: (2,)\n",
      " StripOffsets: (8, 8192, 16376)\n",
      " Orientation: (1,)\n",
      " SamplesPerPixel: (3,)\n",
      " RowsPerStrip: (22,)\n",
      " StripByteCounts: (8184, 8184, 7440)\n",
      " XResolution: ((72, 1),)\n",
      " YResolution: ((72, 1),)\n",
      " PlanarConfiguration: (1,)\n",
      "\n",
      "Metadata for ../Shaggy/images/amalfreda_1.tif:\n",
      " ImageWidth: (124,)\n",
      " ImageLength: (64,)\n",
      " BitsPerSample: (8, 8, 8)\n",
      " Compression: (1,)\n",
      " PhotometricInterpretation: (2,)\n",
      " ResolutionUnit: (2,)\n",
      " StripOffsets: (8, 8192, 16376)\n",
      " Orientation: (1,)\n",
      " SamplesPerPixel: (3,)\n",
      " RowsPerStrip: (22,)\n",
      " StripByteCounts: (8184, 8184, 7440)\n",
      " XResolution: ((72, 1),)\n",
      " YResolution: ((72, 1),)\n",
      " PlanarConfiguration: (1,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inspect the image metadata\n",
    "def get_tiff_metadata(image_input):\n",
    "    if isinstance(image_input, str): # Filepath string\n",
    "        with Image.open(image_input) as img:\n",
    "            return extract_metadata(img)\n",
    "    elif isinstance(image_input, Image.Image): # PIL image\n",
    "        return extract_metadata(image_input)\n",
    "    else:\n",
    "        raise TypeError(\"Input must be a file path or a PIL Image object\")\n",
    "\n",
    "def extract_metadata(img):\n",
    "    metadata = {}\n",
    "\n",
    "    # TIFF tags\n",
    "    for tag, value in img.tag.items():\n",
    "        decoded_tag = TAGS.get(tag, tag)\n",
    "        metadata[decoded_tag] = value\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Load the images using the different methods\n",
    "img_cv2 = cv2.imread('../Shaggy/images/amalfreda_1.tif')\n",
    "img_pil = Image.open('../Shaggy/images/amalfreda_1.tif')\n",
    "img_raw = '../Shaggy/images/amalfreda_1.tif'\n",
    "\n",
    "# Inspect the metadata for the different image representations\n",
    "for img in [img_pil, img_raw]:\n",
    "    print(f\"Metadata for {img}:\")\n",
    "    meta = get_tiff_metadata(img)\n",
    "    for tag, value in meta.items():\n",
    "        print(f\" {tag}: {value}\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec79f65-08fc-42b0-9223-92c5dca2e3b4",
   "metadata": {},
   "source": [
    "It's surprising that the metadata shown for these two representations of the image are identical when we can see their MD5 checksums are different.\n",
    "\n",
    "To see the difference, we need to save the PIL image to disk and load it, since in our PIL MD5 function we save to a buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "449e05a7-cbf6-4af8-bd62-effe17104f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata for saved PIL image:\n",
      " ImageWidth: (124,)\n",
      " ImageLength: (64,)\n",
      " BitsPerSample: (8, 8, 8)\n",
      " Compression: (1,)\n",
      " PhotometricInterpretation: (2,)\n",
      " ResolutionUnit: (2,)\n",
      " StripOffsets: (192,)\n",
      " SamplesPerPixel: (3,)\n",
      " RowsPerStrip: (64,)\n",
      " StripByteCounts: (23808,)\n",
      " XResolution: ((72, 1),)\n",
      " YResolution: ((72, 1),)\n",
      " PlanarConfiguration: (1,)\n",
      "\n",
      "Metadata for saved raw image:\n",
      " ImageWidth: (124,)\n",
      " ImageLength: (64,)\n",
      " BitsPerSample: (8, 8, 8)\n",
      " Compression: (1,)\n",
      " PhotometricInterpretation: (2,)\n",
      " ResolutionUnit: (2,)\n",
      " StripOffsets: (8, 8192, 16376)\n",
      " Orientation: (1,)\n",
      " SamplesPerPixel: (3,)\n",
      " RowsPerStrip: (22,)\n",
      " StripByteCounts: (8184, 8184, 7440)\n",
      " XResolution: ((72, 1),)\n",
      " YResolution: ((72, 1),)\n",
      " PlanarConfiguration: (1,)\n"
     ]
    }
   ],
   "source": [
    "# Demonstrating the issue: inspect the image metadata\n",
    "\n",
    "# Save the PIL image to disk with a \"_pil\" suffix\n",
    "img_pil.save('./amalfreda_1_pil.tif')\n",
    "\n",
    "# Load the saved PIL image and inspect its metadata\n",
    "img_pil_saved = Image.open('./amalfreda_1_pil.tif')\n",
    "print(\"Metadata for saved PIL image:\")\n",
    "meta_pil_saved = get_tiff_metadata(img_pil_saved)\n",
    "for tag, value in meta_pil_saved.items():\n",
    "    print(f\" {tag}: {value}\")\n",
    "print()\n",
    "\n",
    "print(\"Metadata for saved raw image:\")\n",
    "meta_raw = get_tiff_metadata(img_raw)\n",
    "for tag, value in meta_raw.items():\n",
    "    print(f\" {tag}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c1bbc8-a956-4c44-aad2-e655d7d2d5ca",
   "metadata": {},
   "source": [
    "This demonstrates the change in metadata when the PIL object is saved, which causes the MD5 difference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab228577-843f-4b94-bc38-098fdeafb533",
   "metadata": {},
   "source": [
    "However, there are further nuances to be aware of. Using a different method in the function to calculate the checksum of a PIL object yields further differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b8eae75-74e7-4217-8dd0-cfa1d3131530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_md5_checksum2(image):\n",
    "    hash = hashlib.md5()\n",
    "    image_bytes = image.tobytes()    \n",
    "    hash.update(image_bytes)\n",
    "    checksum = hash.hexdigest()\n",
    "    return checksum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ec7d2bb-cd54-4b6f-a96a-b5d43f222c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv2: a2b85e3545d8b525fe20d90ebe5d847e\n",
      "pil: d0dd3bc05dead39e2177c59f2925cd2b\n",
      "pil2: 6c2fa1935394b7489494647bb6ee35b3\n",
      "pil_saved: d0dd3bc05dead39e2177c59f2925cd2b\n",
      "raw: baf9cc4fd984f80dea07ec93308c3a7b\n"
     ]
    }
   ],
   "source": [
    "md5_cv2 = cv2_md5_checksum(img_cv2)\n",
    "md5_pil = pil_md5_checksum(img_pil)\n",
    "md5_pil2 = pil_md5_checksum2(img_pil)\n",
    "md5_pil_saved = pil_md5_checksum(img_pil_saved)\n",
    "md5_raw = file_md5_checksum(img_raw)\n",
    "\n",
    "print(f\"cv2: {md5_cv2}\")\n",
    "print(f\"pil: {md5_pil}\")\n",
    "print(f\"pil2: {md5_pil2}\")\n",
    "print(f\"pil_saved: {md5_pil_saved}\")\n",
    "print(f\"raw: {md5_raw}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5192fb-6fcc-4322-aba2-fa001677e46c",
   "metadata": {},
   "source": [
    "The key is to be sure that data you know to be identical yields matching checksums in small scale tests prior to doing large duplicate searches or other analysis, and to make sure images are loaded using matching methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
